 **缓存（Cache）一词源自法语动词“cacher”，意为“隐藏”。** 将其应用于处理器时，含义显而易见——缓存是处理器用于存储指令和数据的地方，这些数据对程序员和系统是隐藏的。在许多情况下，缓存对你来说是透明的或隐藏的。但正如我们将要看到的，在很多时候，理解缓存的工作原理是非常重要的。

当ARM架构首次开发时，处理器的时钟速度和内存的访问速度大致相当。而今天的处理器核心变得更加复杂，其时钟频率可能比早期处理器快上几个数量级。虽然如此，外部总线和内存设备的频率并没有相应地增长到同样的程度。我们可以实现一些小块的片上SRAM，它们可以与核心以相同的速度运行，然而这种RAM与标准的DRAM相比要昂贵得多，后者的容量可以大上数千倍。在许多基于ARM处理器的系统中，访问外部内存可能需要耗费数十甚至数百个核心周期。

本质上，**缓存（Cache）是一小块快速内存**，它（至少在概念上）位于核心与主存之间。缓存中保存着主存中某些数据项的副本。访问缓存的速度远快于访问主存。由于缓存仅保存主存中内容的一个子集，因此它必须存储主存中数据项的地址及其对应的数据。每当核心需要读取或写入某个特定地址时，它首先会在缓存中查找该地址。如果在缓存中找到该地址，核心将直接使用缓存中的数据，而不必访问主存。这显著提升了系统的潜在性能，因为它减少了由于外部内存访问速度较慢带来的影响。同时，由于避免了驱动外部信号的需求，这也降低了系统的能耗。

缓存的大小相对于系统中使用的整体内存来说较小。更大的缓存会使芯片成本上升。此外，增大核心内部缓存的尺寸可能会限制核心的最大运行速度。因此，**有效使用这一有限资源**是编写高效应用程序以在核心上运行的关键部分。

片上SRAM可以用于实现缓存，缓存保存来自主存的指令和数据的临时副本。代码和数据具有**时间局部性**和**空间局部性**的特性。也就是说，程序往往会随着时间的推移重复使用相同的地址（时间局部性），并且倾向于使用彼此接近的地址（空间局部性）。例如，代码中可能包含循环，这意味着相同的代码会被反复执行，或者某个函数会被多次调用。数据访问（例如对栈的访问）也可能局限于内存的较小区域。正是由于核心访问RAM的过程表现出这种局部性（而非真正的随机访问），缓存才能发挥其作用并取得成功。

**写缓冲区（Write Buffer）**是一个用于解耦核心在执行存储指令时的写操作与外部内存总线的硬件模块。核心将与存储操作相关的地址、控制信息和数据值放入一组硬件缓冲区中。与缓存类似，写缓冲区也位于核心与主存之间。这样，核心可以继续执行下一条指令，而无需等待较慢的主存完成写操作。

### 8.1 为什么缓存有帮助？

正如我们已经讨论过的，**缓存能够加快系统速度**，因为程序的执行并不是随机的。程序通常会反复访问相同的数据集，并重复执行相同的指令集。当代码或数据首次被访问并移动到更快的内存中时，后续对该代码或数据的访问将变得更快。**最初的访问**（将数据加载到缓存的那次）并不会比平常的访问更快，**但后续对缓存中数据的访问**会明显加速，这也是性能提升的来源。

核心硬件会在缓存中检查所有的指令获取和数据读写操作，尽管显然你必须将某些内存区域（例如包含外设设备的部分）标记为**不可缓存**。由于缓存只保存了主存中的一部分内容，因此需要一种方法来**快速判断**你要查找的地址是否在缓存中。

### 8.2 缓存的缺点

虽然缓存和写缓冲区能够加速程序执行，表面上看似乎是自动带来了好处，但它们也引入了一些在**无缓存核心**中不存在的问题。一个明显的缺点是，**程序的执行时间可能变得不确定**。

这是因为缓存较小，只存储了主存的一部分内容，随着程序的执行，缓存会很快被填满。当缓存满了时，现有的代码或数据必须被移除，以腾出空间给新的条目。因此，在某个特定时刻，应用程序通常无法确定某条指令或某个数据项是否在缓存中。

这意味着同一段代码的执行时间可能会有显著的差异。这在要求**强确定性行为**的硬实时系统中可能是个问题。

此外，你需要一种方法来控制缓存和写缓冲区如何访问不同的内存区域。在某些情况下，你希望核心从外部设备（如外设）中读取最新的数据。例如，将一个计时器外设的缓存值用于读取操作显然是不合理的。有时你还希望核心停止并等待存储操作完成。因此，使用缓存和写缓冲区会给你带来额外的工作。

有时，**缓存和外部内存中的内容可能不一致**，这是因为处理器可以更新缓存的内容，而这些内容尚未写回主存。反过来，一个外部代理可能在核心已经缓存了数据后更新主存。这就是所谓的**一致性问题**，特别是在多核心系统或涉及外部DMA控制器等内存代理时，这个问题尤为严重。本书的后续章节将详细描述一致性问题。

### 8.3 内存层次结构

在计算机科学中，**内存层次结构**指的是一种内存类型的层级结构，越靠近核心的内存，其速度越快、容量越小；而越远离核心的内存，其速度越慢、容量越大。在大多数系统中，通常会有二级存储（如磁盘驱动器）和一级存储（如Flash、SRAM和DRAM）。在嵌入式系统中，内存通常被进一步划分为**片上内存**和**片外内存**。与核心在同一芯片（或至少在同一个封装）上的内存通常速度更快。

**缓存（Cache）**可以位于内存层次结构的任何层级，并且在不同内存系统的访问时间存在差异时，可以通过缓存提高系统性能。

在基于ARM处理器的系统中，**一级缓存（L1 Cache）**通常直接连接到核心逻辑中，负责指令获取以及加载和存储操作。这些缓存遵循**哈佛结构（Harvard Cache）**，即指令缓存和数据缓存是分开的，并且它们在功能上表现为核心的一部分。

#### 图8-2 典型的哈佛缓存结构

多年来，随着SRAM容量和速度的提升，L1缓存的大小也有所增加。在撰写本文时，最常见的L1缓存大小为**16KB或32KB**，这些是能够在1GHz或更高的核心速度下提供单周期访问的最大RAM容量。

许多ARM系统还包含**二级缓存（L2 Cache）**，它的容量比L1缓存更大（通常为**256KB、512KB或1MB**），但速度较慢，并且是**统一缓存**（同时存储指令和数据）。L2缓存既可以位于核心内部，也可以作为一个外部模块实现，位于核心与其他内存系统之间。ARM的**L2C-310**就是这样一个外部L2缓存控制器模块的例子。

此外，核心还可以被实现为**集群（Cluster）**，其中每个核心都有自己的L1缓存。这样的系统需要机制来维护缓存的一致性，以确保当一个核心更改了某个内存位置时，这一更改能够对共享该内存的其他核心可见。在我们讨论多核处理器时，会对这些机制进行更详细的介绍。

### 8.4 缓存架构

在**冯·诺依曼架构**中，指令和数据共享一个缓存（即**统一缓存**）。而在**改进的哈佛架构**中，由于指令和数据有独立的总线，因此存在两个缓存：一个是指令缓存（**I-cache**），另一个是数据缓存（**D-cache**）。在许多ARM系统中，一级缓存（L1）通常分为独立的指令缓存和数据缓存，而二级缓存（L2）则是统一缓存。

**缓存**需要存储地址、数据和一些状态信息。32位地址的高位部分告诉缓存该信息来源于主存的哪个位置，这部分信息称为**标记（Tag）**。缓存的总大小是其能够存储的数据量的度量；用于存储标记值的RAM不包含在缓存大小的计算中。然而，标记确实占用了缓存中的物理空间。

如果每个标记地址只存储一个字的数据，这将是非常低效的。因此，通常会将多个位置组合在同一个标记下存储。这个逻辑块通常称为**缓存行（Cache Line）**。地址的中间部分称为**索引（Index）**，用于标识缓存行。索引用于缓存RAM的地址生成，不需要存储在标记中。本章稍后会对此进行更详细的介绍。当缓存行中包含数据或指令时，该行被称为**有效**，反之则为**无效**。

这意味着地址的低几位（**偏移量**）不需要存储在标记中——只需存储整个缓存行的地址，而不是行内每个字节的地址，因此最少5或6位的低位总是为0。

每条缓存行的数据都与一个或多个**状态位**相关联。通常，你会有一个**有效位（Valid Bit）**，用于标记该缓存行是否包含可以使用的数据。（这意味着地址标记代表某个实际值。）在数据缓存中，你可能还会有一个或多个**脏位（Dirty Bit）**，用于标记缓存行（或其部分）是否包含与主存不同（更新）的数据。

#### 8.4.1 缓存术语

以下是一些常用缓存术语的简要总结：
![[Pasted image 20241031215832.png]]

- **缓存行（Line）**：缓存中的最小可加载单元，是主存中连续的多个字（words）组成的一个块。
  
- **索引（Index）**：内存地址的一部分，用于确定该地址在哪些缓存行中可以找到。

- **路（Way）**：缓存的一个子集，每条路的大小相等，并且都采用相同的方式进行索引。与某个特定索引值相关联的每条缓存路中的缓存行组合在一起形成一个**组（Set）**。

- **标记（Tag）**：存储在缓存中的内存地址的一部分，用于标识与某条数据缓存行相关联的主存地址。

#### 8.4.2 直接映射缓存（Direct Mapped Caches）

缓存的实现方式有多种，其中最简单的一种是**直接映射缓存**。

在**直接映射缓存**中，主存中的每个位置都映射到缓存中的某个唯一位置。然而，由于主存的大小远大于缓存，许多内存地址将映射到同一个缓存位置。下图展示了一个小型直接映射缓存，其中每行包含四个字（word），共有四行。
![[Pasted image 20241031220910.png]]

这意味着缓存控制器会使用地址的两位（第[3:2]位）作为**偏移量（Offset）**来选择缓存行中的一个字，并使用地址的两位（第[5:4]位）作为**索引（Index）**来选择四行中的某一行。地址的剩余位（第[31:6]位）将作为**标记（Tag）**值存储。
![[Pasted image 20241031220921.png]]



为了在缓存中查找一个特定的地址，硬件从地址中提取**索引位**，并读取与缓存行相关联的标记值。如果标记值与内存地址匹配，并且**有效位（Valid Bit）**指示该缓存行包含有效数据，则缓存命中（Hit）。此时，可以使用偏移量和字节地址从缓存行中提取数据。

如果缓存行包含有效数据但没有命中（即标记显示缓存中存储的是主存中的其他地址），则缓存行中的数据会被替换为请求地址的数据。

#### 内存抖动问题

可以看出，所有具有相同[5:4]位值的主存地址都会映射到缓存中的同一行。在任何给定时间，缓存中只能存储这些行中的一条数据。这意味着可能会发生一种称为**抖动（Thrashing）**的问题。考虑如下代码中的循环，它反复访问地址`0x00`、`0x40`和`0x80`：

```c
void add_array(int *data1, int *data2, int *result, int size)
{
    int i;
    for (i = 0; i < size; i++) {
        result[i] = data1[i] + data2[i];
    }
}
```

在这个代码示例中，如果`result`、`data1`和`data2`分别指向地址`0x00`、`0x40`和`0x80`，那么这个循环会导致反复访问的内存位置映射到缓存中的同一行，如图8-4所示：

- 当你第一次读取地址`0x40`时，它不在缓存中，因此会触发**行填充**，将地址`0x40`到`0x4F`的数据加载到缓存中。
- 接下来读取地址`0x80`时，它也不在缓存中，于是再次触发行填充，将地址`0x80`到`0x8F`的数据加载到缓存中——同时缓存中的地址`0x40`到`0x4F`的数据被替换。
- 然后将结果写入地址`0x00`。根据分配策略，这可能会触发另一次行填充，且可能导致地址`0x80`到`0x8F`的数据被替换。
- 这种情况会在每次循环迭代中重复发生，最终导致软件性能表现不佳。

**直接映射缓存**因此通常不会用于ARM核心的主缓存中，但在某些地方仍能找到它的应用——例如在ARM1136处理器的**分支目标地址缓存**中。

#### 缓存优化

核心可以对某些情况进行**硬件优化**，例如当整个缓存行被写入时。这种情况在一些系统中可能消耗大量的周期时间。例如，当执行`memcpy()`或`memset()`之类的函数，用于块拷贝或大块的零初始化时，读取即将被覆盖的数据是没有意义的。在这种情况下，缓存的性能特性可能与正常期望的不同。

缓存的**分配策略（Allocate Policy）**只是对核心的提示，并不保证某块内存会被读入缓存。因此，你不应依赖这些策略。

### 8.4.3 组相连缓存（Set Associative Caches）

ARM核心的主缓存通常采用**组相连缓存**（Set Associative Cache）实现。这种缓存结构显著减少了直接映射缓存中常见的**抖动（Thrashing）**问题，从而提高了程序的执行速度并使执行过程更具确定性。代价是增加了硬件的复杂性，并略微增加了功耗（因为在每个周期中需要比较多个标记）。

在这种缓存组织方式中，缓存被划分为若干大小相等的部分，称为**路（Way）**。此时，内存位置映射到某条路而不是具体的缓存行。地址的索引字段仍然用于选择特定的缓存行，但现在它指向每条路中的某一行。常见的实现有**2路**或**4路**组相连缓存，但一些ARM实现中使用了更高的路数。

二级缓存（如ARM的**L2C-310**）可以有更多的路数（即更高的关联度），因为它们的容量更大。具有相同索引值的缓存行被称为属于同一个**组（Set）**。要检查是否命中缓存，你必须查看该组中每条缓存行的标记。

#### 图 8-6 2路组相连缓存

图8-6展示了一个**2路组相连缓存**。地址`0x00`（或`0x40`，或`0x80`）的数据可能会位于两条缓存路中的**某一条**的第0行，而不是同时在两条路中。

#### 增加关联度的影响

增加缓存的关联度可以降低抖动的可能性。**理想的情况是全相连缓存（Fully Associative Cache）**，其中主存中的任何位置都可以映射到缓存中的任何地方。然而，构建这种缓存在实际应用中是不现实的，除非缓存非常小（例如与MMU的**TLB**关联的缓存——详见第9章）。

实际上，对于一级缓存，超过**4路关联**的性能提升非常有限，而对于较大的二级缓存，**8路**或**16路关联**更有用。

### 8.4.4 一个真实的例子

在继续讨论**写缓冲区**之前，先来看一个比前面两个图示更现实的例子。图8-7展示了一个**4路组相连**的**32KB数据缓存**，其缓存行长度为**8个字（8-word）**。这种缓存结构可以在Cortex-A7或Cortex-A9处理器中找到。

缓存行的长度为**8个字**（即32字节），并且有**4路**。32KB的数据缓存除以4（代表4条路），再除以32（每行32字节），得到每条路中有**256行**。这意味着你需要**8位**地址来索引路内的某一行（即地址的[12:5]位）。

此外，你还需要用地址的**[4:2]位**来选择缓存行中的8个字之一，具体需要多少位取决于你访问的是字、半字还是字节。在这种情况下，剩余的地址位**[31:13]**将作为**标记（Tag）**使用。

#### 地址字段划分示例：

- **[31:13]**：标记（Tag）
- **[12:5]**：索引（Index），用于选择路内的一行
- **[4:2]**：偏移量（Offset），用于选择行内的字
### 8.4.5 缓存控制器

**缓存控制器**是一个硬件模块，负责管理缓存内存，其操作对程序大部分是**透明的**。它会自动从主存中将代码或数据写入缓存，并处理来自核心的读写内存请求，执行相应的缓存内存或外部内存操作。

当缓存控制器收到来自核心的请求时，首先需要检查请求的地址是否存在于缓存中，这个过程称为**缓存查找（Cache Look-up）**。它通过将请求地址的一部分与缓存行中的标记（Tag）值进行比较来完成这一过程。如果找到匹配项（称为**缓存命中**），并且该缓存行被标记为有效，则读写操作会使用缓存中的数据完成。

当核心请求某个地址的指令或数据时，如果缓存中的标记不匹配，或者标记无效，则会发生**缓存未命中（Cache Miss）**，此时请求必须传递到内存层次结构的下一级——可能是二级缓存（L2 Cache）或外部存储器。同时，这也可能触发**缓存行填充（Cache Linefill）**。缓存行填充会将主存中的一块数据复制到缓存中，而请求的数据或指令会在填充的同时流入核心。这一过程是透明的，并且对软件开发者不可见。

核心在使用数据时不必等待整个缓存行填充完成。缓存控制器通常会**优先访问缓存行中的关键字（Critical Word）**。例如，当执行一个未命中缓存的加载指令并触发缓存行填充时，核心会首先检索包含请求数据的那部分缓存行。这个关键数据会立即提供给核心流水线，而缓存硬件和外部总线接口则会在后台读取缓存行的剩余部分。

#### 缓存控制器的主要功能：

1. **缓存查找**：比较请求地址的部分位与缓存中的标记值，检查是否命中缓存。
2. **缓存命中**：如果命中缓存且缓存行有效，直接从缓存中读取或写入数据。
3. **缓存未命中**：如果未命中缓存，将请求传递到下一级内存（L2缓存或外部内存），并可能触发缓存行填充。
4. **关键字优先**：在缓存行填充时，优先提供请求的关键数据给核心，而剩余的数据在后台加载。

这样，缓存控制器在提高缓存利用效率的同时，确保核心能够尽快获得所需的关键数据，优化了系统性能。

### 8.4.6 虚拟和物理标记及索引

本节假设读者对地址转换过程有所了解。如果你对虚拟地址不熟悉，建议先阅读第9章后再回来看本节内容。

前面在页面8-9的真实例子中，关于执行缓存查找所使用的确切地址有些不够精确。早期的ARM处理器（如ARM720T或ARM926EJ-S处理器）使用**虚拟地址**来提供索引和标记值。这样做的优点是核心可以不经过虚拟到物理地址的转换直接进行缓存查找。然而，缺点是系统中的虚拟到物理地址映射发生变化时，缓存必须首先被**清除（Clean）并无效化（Invalidate）**，这会对性能产生显著的影响。有关于清除和无效化缓存的更多细节，请参见页面8-17。

**ARM11**系列处理器使用了一种不同的缓存标记方案。在该方案中，缓存的**索引**仍然取自虚拟地址，但**标记（Tag）**取自物理地址。**物理标记（Physical Tagging）**的优势在于，虚拟到物理地址映射的变化不再需要使缓存失效。这对复杂的多任务操作系统非常有利，因为这些系统经常修改翻译表的映射。使用虚拟索引也有一些硬件上的优势，它允许缓存硬件并行读取每条路中的标记值，而无需实际进行虚拟到物理地址的转换，从而实现快速的缓存响应。这类缓存通常被称为**虚拟索引、物理标记（VIPT）**缓存。Cortex-A系列处理器的缓存特性，包括这些标记缓存的使用情况，列在表8-1中。Cortex-A系列处理器的其他属性列在页面2-9的表2-3中。

#### 表 8-1 Cortex-A系列处理器的缓存特性

| 处理器         | L2缓存 | L2缓存大小                  | 数据缓存实现方式 | 指令缓存实现方式 | L1数据缓存大小 | L1指令缓存大小 | L1缓存结构         | L2缓存结构         |
| -------------- | ------ | --------------------------- | ---------------- | -------------- | -------------- | -------------- | ------------------ | ------------------ |
| **Cortex-A5**  | 外部   | -                           | PIPT             | VIPT           | 4K到64K        | 4K到64K        | 2路组相连(指令) <br> 4路组相连(数据) | -                  |
| **Cortex-A7**  | 集成   | 128KB到1MB                  | PIPT             | VIPT           | 8KB到64KB      | 8KB到64KB      | 2路组相连(指令) <br> 4路组相连(数据) | 8路组相连          |
| **Cortex-A8**  | 集成   | 0KB到1MB                    | PIPT             | VIPT           | 16/32KB        | 16/32KB        | 4路组相连         | 8路组相连          |
| **Cortex-A9**  | 外部   | -                           | PIPT             | VIPT           | 16/32/64KB     | 16/32/64KB     | 4路组相连         | -                  |
| **Cortex-A12** | 集成   | 256KB到8MB                  | PIPT             | VIPT           | 32KB           | 32KB或64KB     | 4路组相连         | 16路组相连         |
| **Cortex-A15** | 集成   | 512KB到4MB                  | PIPT             | PIPT           | 32KB           | 32KB           | 2路组相连         | 16路组相连         |

#### VIPT缓存的缺点

VIPT实现方式存在一个缺点。对于**4路组相连**的32KB或64KB缓存，地址的**[12]和[13]位**用于选择索引。如果MMU中使用的是4KB的页表，虚拟地址的**[13:12]位**可能与物理地址的**[13:12]位不相同**。因此，如果多个虚拟地址映射到同一个物理地址，可能会出现**缓存一致性问题**。为了解决这一问题，内核的地址转换表软件必须遵守某些限制。这被称为**页着色问题（Page Coloring Issue）**，在其他处理器架构中也因类似的原因存在。

这个问题可以通过使用**物理索引、物理标记（PIPT）**缓存实现来避免。Cortex-A系列处理器的数据缓存采用了这种方案。这样可以避免页着色问题，但代价是增加了硬件复杂性。


### 8.6 写缓冲和取缓冲

写缓冲是核心内部的一个硬件模块（有时也存在于系统的其他部分），通过多个缓冲区实现。它接受与核心写入内存相关的地址、数据和控制信息。当核心执行存储指令时，它可能会将相关的细节，例如写入位置、要写入的数据和事务大小等，放入缓冲区。核心无需等待写入操作完成即可继续执行下一条指令。写缓冲会自动将核心传递的写操作排空到内存系统中。

写缓冲可以提高系统的性能。它通过使核心不必等待存储操作完成来实现性能提升。实际上，只要写缓冲有可用空间，写缓冲就是一种隐藏延迟的手段。如果写操作较少或间隔较大，写缓冲不会被填满。但如果核心生成写操作的速度超过写缓冲排空到内存的速度，写缓冲最终会被填满，性能提升也会变小。

有些写缓冲支持写合并（也称为写组合）。它们可以将多个写操作（例如对相邻字节的写入流）合并为一个单独的突发传输。这可以减少对外部内存的写入流量，从而提高性能。

显然，在访问外设时，有时写缓冲的行为并不是你所期望的。你可能希望核心在写入完成之前停止并等待，才继续执行下一步操作。有时你可能确实希望一个字节流被逐个写入，而不希望存储操作被合并。ARM的内存排序模型（详见第10-3页）描述了ARM架构支持的内存类型，以及如何使用这些类型来控制缓存和写缓冲在特定设备或内存映射部分的使用。

在某些系统中，类似的组件（称为取缓冲）可以用于读取操作。尤其是，核心通常包含预取缓冲，它们在指令被插入流水线之前，从内存中预先读取指令。通常，这类缓冲对你是透明的。我们将在讨论内存排序规则时，考虑与此相关的潜在风险。

### 8.7 缓存性能和命中率

命中率定义为缓存命中次数与在指定时间内对缓存的内存请求次数之比，通常以百分比计算。同样，丢失率是缓存缺失次数与内存请求总次数之比。人们还可以仅计算读取或写入操作的命中或丢失次数。显然，较高的命中率通常会带来更高的性能。对于典型软件来说，无法给出具体的示例数据，命中率主要取决于代码或数据的关键部分的大小和空间局部性，当然还取决于缓存的大小。

有一些简单的规则可以遵循以获得更好的性能。最明显的规则就是启用缓存和写缓冲，并尽可能使用它们（通常适用于包含代码的所有内存系统部分，通常是RAM和ROM，但不适用于外设）。在Cortex-A系列处理器中，如果指令内存被缓存，性能将显著提高。将频繁访问的数据放在内存中靠近的位置也会有所帮助。例如，一个频繁访问的数组可以通过将其基地址设置在缓存行的起始位置来获益。

从内存中获取数据值涉及获取整个缓存行；如果缓存行中的其他字没有被使用，那么性能提升将很小甚至没有。这可以通过‘缓存友好’的方式访问数据来缓解。例如，顺序地址访问（如访问数组的一行）将从缓存行为中受益，而不可预测或非顺序的访问模式（如链表）则不会。

较小的代码可能比较大的代码更适合缓存，有时这会产生看似矛盾的结果。例如，一段用C语言编写的代码在编译为Thumb（或最小尺寸）时可能完全适合缓存，而编译为ARM（或最大性能）时却不适合缓存，因此，较小的版本可能比优化后的版本运行得更快。

### 8.8 使缓存失效与清理缓存

当外部内存的内容发生变化，并且你希望从缓存中删除陈旧数据时，可能需要进行缓存清理和失效操作。这些操作也可能在与MMU（内存管理单元）相关的活动之后需要执行，例如更改访问权限、缓存策略或虚拟地址到物理地址的映射时。

在描述清理和失效操作时，术语“刷新”经常被使用。而ARM通常只使用“清理”和“失效”这两个术语：

- **缓存失效**或缓存行失效意味着清除其中的数据。这是通过清除一个或多个缓存行的有效位来完成的。缓存必须在复位后总是被失效，因为此时缓存的内容是未定义的。如果缓存中包含脏数据，直接失效通常是不正确的。对写回缓存区域进行的写操作的任何更新数据都将因简单的失效操作而丢失。

- **清理缓存**或缓存行清理意味着将脏缓存行的内容写回主内存，并清除缓存行中的脏位。这使缓存行的内容与主内存保持一致。这仅适用于使用写回策略的数据缓存。缓存失效和缓存清理操作可以按缓存集、缓存路或虚拟地址执行。

从一个位置复制代码到另一个位置（或其他形式的自修改代码）可能需要你清理和/或使缓存失效。内存复制代码使用加载和存储指令，而这些指令将在核心的数据侧操作。如果数据缓存使用写回策略写入代码的区域，则在执行代码之前，必须先将该区域的数据清理出缓存。这确保了作为数据存储的指令被写入主内存，然后供指令获取逻辑使用。此外，如果写入代码的区域之前用于其他程序，指令缓存可能包含陈旧的代码（在主内存重写之前）。因此，在跳转到新的复制代码之前，可能还需要使指令缓存失效。

清理或失效缓存的命令是通过CP15操作实现的。这些操作仅对特权代码可用，不能在用户模式下执行。在使用TrustZone安全扩展的系统中，某些操作的非安全使用可能会受到硬件限制。

CP15指令可以对一级数据或指令缓存进行清理、失效或清理并失效操作。仅在缓存中没有脏数据时，失效操作才是安全的——例如，针对哈佛架构的指令缓存，或者当数据即将被覆盖且你不关心丢失以前的值时。你可以对整个缓存或单个缓存线执行这些操作。这些单个缓存线可以通过给定的虚拟地址来指定（用于清理或失效），或者在硬件结构已知的情况下，通过指定特定集合中的缓存线号来指定。同样的操作也可以在L2或外部缓存上执行，我们将在**8-22页的“二级缓存控制器”**中进一步讨论。一个典型的代码示例可以在**13-3页的“设置缓存、MMU和分支预测器”**中找到。

#### 示例 8-1 缓存准备操作

```assembly
setup_caches
 MRC p15, 0, r1, c1, c0, 0           ; 读取系统控制寄存器（SCTLR）
 BIC r1, r1, #1                      ; 关闭MMU
 BIC r1, r1, #(1 << 12)              ; 关闭I-cache
 BIC r1, r1, #(1 << 2)               ; 关闭D-cache & L2缓存
 MCR p15, 0, r1, c1, c0, 0           ; 写入系统控制寄存器（SCTLR）
;----------------------------------------------
; 1. 关闭MMU、L1缓存
;----------------------------------------------
 MRC p15, 0, r1, c1, c0, 0           ; 读取系统控制寄存器（SCTLR）
 BIC r1, r1, #1                      ; 关闭MMU
 BIC r1, r1, #(1 << 12)              ; 关闭I-cache
 BIC r1, r1, #(1 << 2)               ; 关闭D-cache & L2缓存
 MCR p15, 0, r1, c1, c0, 0           ; 写入系统控制寄存器（SCTLR）
;----------------------------------------------
; 2. 使L1缓存、TLB、分支预测器失效
;----------------------------------------------
 MOV     r0, #0
 MCR     p15, 0, r0, c7, c5, 0       ; 使指令缓存失效
 MCR     p15, 0, r0, c7, c5, 6       ; 使分支预测数组失效
 MCR     p15, 0, r0, c8, c7, 0       ; 使整个统一主TLB失效
 ISB                                ; 指令同步屏障
;----------------------------------------------
; 2.a. 启用I-cache和分支预测
;----------------------------------------------
 MRC     p15, 0, r0, c1, c0, 0           ; 读取系统控制寄存器
 ORR     r0, r0, #1 << 12                ; 启用指令缓存
 ORR     r0, r0, #1 << 11                ; 启用程序流预测
 MCR     p15, 0, r0, c1, c0, 0           ; 写入系统控制寄存器
```

当然，这些操作将通过内核代码来访问——在Linux的GCC中，你可以使用`__clear_cache()`函数，该函数在`arch/arm/mm/cache-v7.S`中实现：

```c
void __clear_cache(char* beg, char* end);
```

起始地址（`char* beg`）是包含的，而结束地址（`char* end`）是不包含的。其他操作系统中也有类似的函数，例如，Google Android中有`cacheflush()`函数。

一个常见的需要进行缓存清理或失效的情况是DMA（直接内存访问）。当需要使核心的更改对外部内存可见，以便DMA控制器可以读取时，可能需要清理缓存。当DMA控制器写入外部内存并且需要使这些更改对核心可见时，必须使相关地址在缓存中失效。 

### 8.9 一致性点和统一性点

对于基于集合/路的缓存清理和失效操作，操作是在特定的缓存级别上执行的。对于使用虚拟地址的操作，架构定义了两个概念点：

#### 一致性点 (Point of Coherency, PoC)

对于某个特定地址，一致性点是所有能够访问该内存的组件（例如核心、DSP 或 DMA 引擎）能够保证看到同一个内存位置副本的点。通常，这个点位于主外部系统内存。

#### 统一性点 (Point of Unification, PoU)

对于一个核心，统一性点是该核心的指令缓存和数据缓存能够保证看到同一个内存位置副本的点。例如，在具有 Harvard 架构的一级缓存和用于缓存翻译表项的 TLB 的系统中，统一的二级缓存将是统一性点。如果没有外部缓存，主内存将是统一性点。

在 Cortex-A9 处理器中，PoC 和 PoU 实质上是位于同一位置，即 L2 接口处。

由于 Cortex-A8 处理器包含了由 CP15 控制的 L2 缓存，PoU 和 PoC 分别位于不同的位置：PoU 位于 L2 缓存内，而 PoC 位于 L2 接口外部。

对于不熟悉硬件翻译表遍历（Hardware Translation Table Walk）或翻译后备缓冲（Translation Lookaside Buffer, TLB）的读者，可以在第9章找到相关描述。如果没有外部缓存，主内存将是 PoU。

在集群或 big.LITTLE 组合的情况下，PoU 是集群中所有核心的指令缓存、数据缓存和翻译表遍历能够保证看到同一内存位置副本的点。

了解 PoU 可以帮助自修改代码确保后续的指令获取操作从修改后的代码进行。可以通过以下两步来实现：

- 清理相关的数据缓存条目（按地址）。
- 使指令缓存条目失效（按地址）。

此外，还需要使用内存屏障。

---


以下代码展示了一个清理整个数据缓存或统一缓存至一致性点的通用机制。

> **注意**  
> 在多个核心共享一致性点之前的缓存的集群中，如果在多个核心上运行此序列，则会在共享缓存上重复执行这些操作。

```
MRC p15, 1, R0, c0, c0, 1        ; 将 CLIDR 读入 R0
ANDS R3, R0, #0x07000000
MOV R3, R3, LSR #23              ; 获取缓存级别值（自然对齐）
BEQ Finished                     ; 如果没有缓存级别，跳转到结束
MOV R10, #0                      ; 初始化缓存级别计数器

Loop1
ADD R2, R10, R10, LSR #1         ; 计算3倍缓存级别
MOV R1, R0, LSR R2               ; 底部3位为该级别的缓存类型
AND R1, R1, #7                   ; 获取缓存类型
CMP R1, #2
BLT Skip                         ; 如果无缓存或只有指令缓存，跳过

MCR p15, 2, R10, c0, c0, 0       ; 将R10写入 CSSELR
ISB                              ; ISB 同步更改至 CCSIDR
MRC p15, 1, R1, c0, c0, 0        ; 将当前 CCSIDR 读入 R1
AND R2, R1, #7                   ; 提取缓存行长度字段
ADD R2, R2, #4                   ; 添加 4 以获取缓存行长度偏移（log2 16 字节）
LDR R4, =0x3FF
ANDS R4, R4, R1, LSR #3          ; R4 为最大路径数（右对齐）
CLZ R5, R4                       ; R5 为路径大小增量的位位置
MOV R9, R4                       ; R9 为最大路径数的工作副本

Loop2
LDR R7, =0x00007FFF
ANDS R7, R7, R1, LSR #13         ; R7 为最大索引号（右对齐）

Loop3
ORR R11, R10, R9, LSL R5         ; 将路径号和缓存号合并到 R11
ORR R11, R11, R7, LSL R2         ; 将索引号合并到 R11
MCR p15, 0, R11, c7, c10, 2      ; DCCSW，按集合/路清理
SUBS R7, R7, #1                  ; 索引递减
BGE Loop3                        ; 如果索引还未到 0，继续

SUBS R9, R9, #1                  ; 路径递减
BGE Loop2                        ; 如果路径还未到 0，继续

ADD R10, R10, #2                 ; 缓存级别递增
CMP R3, R10
BGT Loop1                        ; 如果还有缓存级别，继续

DSB                              ; 数据同步屏障
Finished
```

类似地，你可以使用清理数据缓存条目和使 TLB 失效的操作，以确保对翻译表的所有写入对 MMU 可见。


### 8.10 二级缓存控制器

在本章的开头，我们简要介绍了内存系统的分区，并解释了许多系统如何具有多级缓存层次结构。然而，Cortex-A5 和 Cortex-A9 处理器并不集成二级缓存。相反，系统设计师可以选择将另一个缓存控制器（例如 ARM 的 L2 缓存控制器 L2C-310）连接到处理器实例之外。

L2C-310 缓存控制器可以支持最大 8MB 大小的缓存，组相联度在四路到十六路之间。缓存的大小和相联度由 SoC 设计师固定。二级缓存可以在多个核心之间共享，甚至可以在核心与其他组件（例如图形处理器）之间共享。它还支持基于每个主设备、每条路的缓存数据锁定，从而实现对多个组件之间缓存共享的管理。

#### 8.10.1 二级缓存维护

在**8-11 页的“虚拟和物理标签与索引”**中描述了为何你可能需要清理或使缓存的部分或全部失效。当缓存位于核心外部时，可以通过向二级缓存控制器内的内存映射寄存器写入数据来完成此操作；当二级缓存在核心内部实现时，则可以通过 CP15 指令来完成。这些寄存器本身没有被缓存，这使得执行这些操作成为可能。当通过核心执行内存映射写操作时，核心必须有一种方式来确定操作何时完成。核心通过轮询 L2 缓存控制器内的另一个内存映射寄存器来完成这一任务。

ARM L2C-310 二级缓存控制器仅对物理地址进行操作。因此，为了执行缓存维护操作，程序可能需要执行虚拟地址到物理地址的转换。L2C-310 提供了一个缓存同步操作，用于强制系统等待未完成的操作完成。

---

### 8.11 缓存中的奇偶校验和纠错码 (ECC)

所谓的软错误正日益成为一个关注点。较小的晶体管几何尺寸和较低的电压使电路对宇宙射线、其他背景辐射、来自硅封装的α粒子或电气噪声的干扰更加敏感。对于依赖于存储少量电荷且占据大部分硅片面积的内存设备来说，这尤其明显。如果不采取适当的软错误防护措施，某些系统的平均故障间隔时间可能会以秒为单位测量。

ARM 架构在缓存中提供了对奇偶校验和纠错码 (ECC) 的支持。**奇偶校验**意味着存在一个额外的位，根据所选方案，该位标记具有值 1 的位的数量是偶数还是奇数。这提供了一种简单的单比特错误检测方法。

**ECC** 方案则可以检测多比特故障，并且可能从软错误中恢复。但恢复计算可能需要多个周期。实现一个能够容忍一级缓存 RAM 访问需要多个时钟周期的核心会显著增加设计的复杂性。因此，ECC 通常仅在核心外部的内存块上使用（例如二级缓存）。然而，Cortex-A15 在核心内部支持 ECC 和奇偶校验。

奇偶校验在读写时进行检查，并且可以在标签 RAM 和数据 RAM 上实现。奇偶校验不匹配会触发预取或数据中止异常，并相应地更新故障状态地址寄存器。

---

版权 © 2011 – 2013 ARM公司。保留所有权利。